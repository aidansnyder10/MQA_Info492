**Class Feedback**

The class feedback provided detailed insights that helped our team validate and refine our hypothesis that LLM-powered agents can scale highly personalized spear-phishing at low cost. Many peers recognized that our project showed significant improvement from the early demos, especially in turning a conceptual idea into a measurable, data-driven experiment. They noted that the AI-generated phishing emails appeared more convincing and coherent than manually written ones, which supports the core idea that LLMs can effectively mimic legitimate communication styles. Reviewers also praised our integration of multiple LLMs through OpenRouter and the use of persona-based targeting, which made the experiment more realistic and aligned with how real attackers might operate.

A major strength identified was our Deception Quality Score (DQS) framework. Students highlighted that automating evaluation across factors like coherence, urgency, and evasion added rigor and scalability to our analysis. They appreciated that the DQS rubric and statistical comparisons between AI and human emails made our experiment credible and transparent.

However, feedback also revealed areas for improvement. Several reviewers questioned whether higher DQS scores actually correlate with real human behavior, such as clicks or reports, and suggested testing how deliverability and spam filters might affect success rates. Based on these insights, our team plans to strengthen validation by simulating behavioral responses through controlled environments with seeded inboxes, synthetic personas, and consenting evaluators. This approach will help bridge the gap between algorithmic scoring and realistic human interaction, leading to a fuller validation of our hypothesis.